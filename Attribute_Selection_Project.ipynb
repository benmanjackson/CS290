{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/benmanjackson/CS290/blob/main/Attribute_Selection_Project.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Khush Dakwala and Benjamin Jackson"
      ],
      "metadata": {
        "id": "J_uCNDcCjAyR"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lTjgxHHQVQVL"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from collections import Counter\n",
        "\n",
        "# Entropy calculation function\n",
        "def calculate_entropy(y):\n",
        "    counts = Counter(y)\n",
        "    total = len(y)\n",
        "    entropy = -sum((count / total) * np.log2(count / total) for count in counts.values())\n",
        "    return entropy\n",
        "\n",
        "# Gini impurity calculation function\n",
        "def calculate_gini(y):\n",
        "    counts = Counter(y)\n",
        "    total = len(y)\n",
        "    gini = 1 - sum((count / total) ** 2 for count in counts.values())\n",
        "    return gini\n",
        "\n",
        "# Mean Squared Error (MSE) calculation for regression\n",
        "def calculate_mse(y):\n",
        "    mean_y = np.mean(y)\n",
        "    mse = np.mean((y - mean_y) ** 2)\n",
        "    return mse\n",
        "\n",
        "# Split dataset based on a feature and threshold\n",
        "def split_dataset(X, y, feature_idx, threshold):\n",
        "    left_split = [i for i in range(len(X)) if X[i][feature_idx] <= threshold]\n",
        "    right_split = [i for i in range(len(X)) if X[i][feature_idx] > threshold]\n",
        "    return left_split, right_split\n",
        "\n",
        "# Calculate the weighted impurity after a split\n",
        "def calculate_weighted_impurity(y, left_indices, right_indices, impurity_func):\n",
        "    left_impurity = impurity_func([y[i] for i in left_indices])\n",
        "    right_impurity = impurity_func([y[i] for i in right_indices])\n",
        "    left_weight = len(left_indices) / len(y)\n",
        "    right_weight = len(right_indices) / len(y)\n",
        "    weighted_impurity = left_weight * left_impurity + right_weight * right_impurity\n",
        "    return weighted_impurity\n",
        "\n",
        "# Main function to find the best attribute and threshold\n",
        "def Attribute_selection_method(task, dataset, target_var, criterion=None):\n",
        "    # Separate features and target\n",
        "    X = dataset.drop(columns=[target_var]).values\n",
        "    y = dataset[target_var].values\n",
        "\n",
        "    best_feature = None\n",
        "    best_threshold = None\n",
        "    best_impurity = float('inf')\n",
        "\n",
        "    # Define impurity function based on task\n",
        "    if task == \"classification\":\n",
        "        if criterion == \"entropy\":\n",
        "            impurity_func = calculate_entropy\n",
        "        elif criterion == \"gini\":\n",
        "            impurity_func = calculate_gini\n",
        "        else:\n",
        "            raise ValueError(\"Invalid criterion for classification. Choose 'entropy' or 'gini'.\")\n",
        "    elif task == \"regression\":\n",
        "        impurity_func = calculate_mse\n",
        "    else:\n",
        "        raise ValueError(\"Invalid task type. Choose 'classification' or 'regression'.\")\n",
        "\n",
        "    # Loop over each feature\n",
        "    for feature_idx in range(X.shape[1]):\n",
        "        # Get all unique values of the feature for splitting\n",
        "        unique_values = np.unique(X[:, feature_idx])\n",
        "\n",
        "        # Try each unique value as a threshold\n",
        "        for threshold in unique_values:\n",
        "            left_indices, right_indices = split_dataset(X, y, feature_idx, threshold)\n",
        "\n",
        "            # Skip if one side of the split is empty\n",
        "            if not left_indices or not right_indices:\n",
        "                continue\n",
        "\n",
        "            # Calculate weighted impurity for the split\n",
        "            weighted_impurity = calculate_weighted_impurity(y, left_indices, right_indices, impurity_func)\n",
        "\n",
        "            # Update the best split if this one is better\n",
        "            if weighted_impurity < best_impurity:\n",
        "                best_impurity = weighted_impurity\n",
        "                best_feature = feature_idx\n",
        "                best_threshold = threshold\n",
        "\n",
        "    # Return the best feature and threshold\n",
        "    if best_feature is not None:\n",
        "        return dataset.columns[best_feature], best_threshold\n",
        "    else:\n",
        "        return None, None\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Applying the method to Categorical and Numerical targets and comparing the split chosen between our method and sklearn's."
      ],
      "metadata": {
        "id": "r1gvIO2vLRm5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.tree import DecisionTreeClassifier, DecisionTreeRegressor\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.pipeline import Pipeline\n",
        "import numpy as np\n",
        "# Load the dataset\n",
        "url = 'https://raw.githubusercontent.com/dreamingv-oid/CS290/main/train.csv'\n",
        "df = pd.read_csv(url)\n",
        "\n",
        "# Strip any whitespace characters from column names\n",
        "df.columns = df.columns.str.strip()\n",
        "\n",
        "# Drop rows with missing values\n",
        "df.dropna(inplace=True)\n",
        "\n",
        "# Apply the method to the classification dataset\n",
        "# Create a copy of the DataFrame for classification\n",
        "df_classification = df.copy()\n",
        "best_feature_classification = Attribute_selection_method(\"classification\", df_classification, \"satisfaction\", criterion=\"gini\")\n",
        "\n",
        "# Fit sklearn's DecisionTreeClassifier to compare first split\n",
        "X_classification = df_classification.drop(columns=[\"satisfaction\"])\n",
        "y_classification = df_classification[\"satisfaction\"]\n",
        "\n",
        "# Create and fit the classifier within a pipeline\n",
        "classifier = Pipeline(steps=[\n",
        "    ('preprocessor', ColumnTransformer(\n",
        "        transformers=[\n",
        "            ('cat', OneHotEncoder(handle_unknown='ignore'), X_classification.select_dtypes(include=['object']).columns)\n",
        "        ], remainder='passthrough'\n",
        "    )),\n",
        "    ('model', DecisionTreeClassifier(criterion=\"gini\", random_state=42))\n",
        "])\n",
        "\n",
        "classifier.fit(X_classification, y_classification)\n",
        "\n",
        "# Get the first split chosen by sklearn's DecisionTreeClassifier\n",
        "first_split_classification = classifier.named_steps['model'].tree_.feature[classifier.named_steps['model'].tree_.children_left[0]]\n",
        "\n",
        "# Apply the method to the regression dataset\n",
        "# Create a copy of the DataFrame for regression\n",
        "df_regression = df.copy()\n",
        "best_feature_regression = Attribute_selection_method(\"regression\", df_regression, \"Flight Distance\")\n",
        "\n",
        "# Fit sklearn's DecisionTreeRegressor to compare first split\n",
        "X_regression = df_regression.drop(columns=[\"Flight Distance\"])\n",
        "y_regression = df_regression[\"Flight Distance\"]\n",
        "\n",
        "# Create and fit the regressor within a pipeline\n",
        "regressor = Pipeline(steps=[\n",
        "    ('preprocessor', ColumnTransformer(\n",
        "        transformers=[\n",
        "            ('cat', OneHotEncoder(handle_unknown='ignore'), X_regression.select_dtypes(include=['object']).columns)\n",
        "        ], remainder='passthrough'\n",
        "    )),\n",
        "    ('model', DecisionTreeRegressor(criterion=\"squared_error\", random_state=42))\n",
        "])\n",
        "\n",
        "regressor.fit(X_regression, y_regression)\n",
        "\n",
        "# Get the first split chosen by sklearn's DecisionTreeRegressor\n",
        "first_split_regression = regressor.named_steps['model'].tree_.feature[regressor.named_steps['model'].tree_.children_left[0]]\n",
        "\n",
        "# Print the results together\n",
        "print(f\"Best splitting criterion for classification (Gini) via our method: {best_feature_classification}\")\n",
        "print(f\"Best splitting criterion for regression via our method: {best_feature_regression}\")\n",
        "\n",
        "# Print sklearn's first split features\n",
        "print(f\"First split feature chosen by sklearn's DecisionTreeClassifier: {X_classification.columns[first_split_classification]}\")\n",
        "print(f\"First split feature chosen by sklearn's DecisionTreeRegressor: {X_regression.columns[first_split_regression]}\")"
      ],
      "metadata": {
        "id": "43f-vC84VWK5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "L4h6DbU6wc5O"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}